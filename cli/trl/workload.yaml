experiment_name: trl-sft-qwen2

environment:
  dependencies: requirements.yaml
  env_variables:
    NCCL_DEBUG: "INFO"
    MLFLOW_TRACKING_URI: "databricks"
  env_variables_secrets:
    # change this to your databricks secret "scope/your_secret" that stores the huggingface token
    HF_TOKEN: "sgc-nightly-notebook/hf_token"

compute:
  gpus: 8
  gpu_type: h100

max_retries: 0

code_source:
  type: snapshot
  snapshot:
    # change this to your local repo path
    repo_path: /Users/q.yu/databricks-SGC-Axolotl-examples

command: |-
  # TRL SFT training with accelerate for distributed training
  accelerate launch \
    --num_machines 1 \
    --num_processes $WORLD_SIZE \
    --machine_rank $NODE_RANK \
    --main_process_ip $MASTER_ADDR \
    --main_process_port $MASTER_PORT \
    --mixed_precision bf16 \
    $HOME/databricks-SGC-Axolotl-examples/cli/trl/sft.py \
    --model_name_or_path Qwen/Qwen2-0.5B \
    --dataset_name trl-lib/Capybara \
    --learning_rate 2.0e-5 \
    --num_train_epochs 1 \
    --packing \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 8 \
    --eos_token '<|im_end|>' \
    --eval_strategy steps \
    --eval_steps 100 \
    --output_dir Qwen2-0.5B-SFT
